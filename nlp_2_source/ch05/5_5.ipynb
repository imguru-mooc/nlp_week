{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNLM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNLM의 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "[0 1 2 3 4 1 5 6]\n",
      "[0 1 2 3 4 1 5]\n",
      "[1 2 3 4 1 5 6]\n",
      "7\n",
      "[0]\n",
      "[[0 1 2]]\n",
      "[[1 2 3]]\n",
      "loss =  1.9406665166219075\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "temp = \"you say goodbye and i say hello .\"\n",
    "words = temp.split()\n",
    "print(words)\n",
    "\n",
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "for i, word in enumerate(words):\n",
    "    if word not in word_to_id:\n",
    "        tmp_id = len(word_to_id)\n",
    "        word_to_id[word] = tmp_id\n",
    "        id_to_word[tmp_id] = word\n",
    "\n",
    "print(word_to_id)\n",
    "corpus = np.array([word_to_id[w] for w in words])\n",
    "print(corpus)\n",
    "\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]   # 출력(정답 레이블)\n",
    "print(xs)\n",
    "print(ts)\n",
    "\n",
    "batch_size = 1\n",
    "corpus_size = len(corpus)\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "print(jump)\n",
    "print(offsets)\n",
    "\n",
    "data_size = len(xs)\n",
    "time_size = 3\n",
    "time_idx = 0\n",
    "# 미니배치 취득\n",
    "batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "for t in range(time_size):\n",
    "    for i, offset in enumerate(offsets):\n",
    "        batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "        batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "    time_idx += 1\n",
    "    \n",
    "print(batch_x)\n",
    "print(batch_t)\n",
    "\n",
    "lr = 0.1\n",
    "model = SimpleRnnlm(vocab_size=7, wordvec_size=4, hidden_size=3)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "loss = model.forward(batch_x, batch_t)\n",
    "print(\"loss = \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "[[[ 0.  1.  2.  3.]\n",
      "  [ 4.  5.  6.  7.]\n",
      "  [ 8.  9. 10. 11.]]]\n"
     ]
    }
   ],
   "source": [
    "out = np.empty((1, 3, 4), dtype='f')\n",
    "print(out[:,0,:].shape)\n",
    "embed_W = np.arange(28).reshape(7,4)\n",
    "\n",
    "for t in range(3):\n",
    "    idx = [t]\n",
    "    out[:,t,:] = embed_W[idx]  # (1,4) = (1,4)\n",
    "    \n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929588,)\n",
      "(929589,)\n",
      "말뭉치 크기: 1000, 어휘 수: 10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9def054b306f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m#         print(batch_x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# 기울기를 구하여 매개변수 갱신\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Dropbox\\자연어처리_주말과정\\nlp_2_source\\ch05\\simple_rnnlm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xs, ts)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Dropbox\\자연어처리_주말과정\\nlp_2_source\\common\\time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xs)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Dropbox\\자연어처리_주말과정\\nlp_2_source\\common\\layers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, W)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mzeros_like\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mzeros_like\u001b[1;34m(a, dtype, order, subok, shape)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;31m# needed instead of a 0 to get same result as zeros for for string dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unsafe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcopyto\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5     # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "# max_epoch = 1\n",
    "# 학습 데이터 읽기(전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "# corpus_size = 1000\n",
    "# corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]   # 출력(정답 레이블)\n",
    "data_size = len(xs)\n",
    "print(xs.shape)\n",
    "print(corpus.shape)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "# max_iters = 1\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# 미니배치의 각 샘플의 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # 미니배치 취득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "#         print(batch_x.shape)\n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # 에폭마다 퍼플렉서티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| 에폭 %d | 퍼플렉서티 %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNLM의 Trainer 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 417.96\n",
      "| 에폭 2 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 386.34\n",
      "| 에폭 3 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 265.03\n",
      "| 에폭 4 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 220.74\n",
      "| 에폭 5 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 209.24\n",
      "| 에폭 6 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 207.66\n",
      "| 에폭 7 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 201.12\n",
      "| 에폭 8 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 201.50\n",
      "| 에폭 9 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 195.67\n",
      "| 에폭 10 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 191.33\n",
      "| 에폭 11 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 193.86\n",
      "| 에폭 12 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 190.33\n",
      "| 에폭 13 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 193.92\n",
      "| 에폭 14 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 189.20\n",
      "| 에폭 15 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 188.25\n",
      "| 에폭 16 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 193.14\n",
      "| 에폭 17 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 191.07\n",
      "| 에폭 18 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 186.81\n",
      "| 에폭 19 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 183.16\n",
      "| 에폭 20 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 183.77\n",
      "| 에폭 21 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 181.16\n",
      "| 에폭 22 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 180.66\n",
      "| 에폭 23 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 182.81\n",
      "| 에폭 24 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 181.01\n",
      "| 에폭 25 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 174.46\n",
      "| 에폭 26 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 176.46\n",
      "| 에폭 27 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 174.87\n",
      "| 에폭 28 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 174.45\n",
      "| 에폭 29 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 169.13\n",
      "| 에폭 30 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 165.70\n",
      "| 에폭 31 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 165.39\n",
      "| 에폭 32 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 159.99\n",
      "| 에폭 33 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 158.89\n",
      "| 에폭 34 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 158.89\n",
      "| 에폭 35 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 151.06\n",
      "| 에폭 36 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 149.26\n",
      "| 에폭 37 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 150.24\n",
      "| 에폭 38 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 141.50\n",
      "| 에폭 39 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 137.02\n",
      "| 에폭 40 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 132.75\n",
      "| 에폭 41 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 128.39\n",
      "| 에폭 42 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 128.74\n",
      "| 에폭 43 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 121.27\n",
      "| 에폭 44 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 117.27\n",
      "| 에폭 45 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 109.42\n",
      "| 에폭 46 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 107.67\n",
      "| 에폭 47 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 105.05\n",
      "| 에폭 48 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 99.59\n",
      "| 에폭 49 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 96.54\n",
      "| 에폭 50 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 89.47\n",
      "| 에폭 51 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 87.83\n",
      "| 에폭 52 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 81.94\n",
      "| 에폭 53 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 79.22\n",
      "| 에폭 54 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 75.67\n",
      "| 에폭 55 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 71.00\n",
      "| 에폭 56 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 67.77\n",
      "| 에폭 57 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 66.59\n",
      "| 에폭 58 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 61.09\n",
      "| 에폭 59 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 58.30\n",
      "| 에폭 60 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 54.94\n",
      "| 에폭 61 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 51.20\n",
      "| 에폭 62 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 48.25\n",
      "| 에폭 63 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 47.13\n",
      "| 에폭 64 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 44.98\n",
      "| 에폭 65 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 40.43\n",
      "| 에폭 66 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 39.80\n",
      "| 에폭 67 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 36.58\n",
      "| 에폭 68 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 34.76\n",
      "| 에폭 69 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 32.68\n",
      "| 에폭 70 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 30.51\n",
      "| 에폭 71 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 28.68\n",
      "| 에폭 72 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 27.00\n",
      "| 에폭 73 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 25.65\n",
      "| 에폭 74 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 23.85\n",
      "| 에폭 75 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 23.40\n",
      "| 에폭 76 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 21.76\n",
      "| 에폭 77 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 21.26\n",
      "| 에폭 78 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 19.60\n",
      "| 에폭 79 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 18.10\n",
      "| 에폭 80 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 16.69\n",
      "| 에폭 81 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 15.92\n",
      "| 에폭 82 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 15.38\n",
      "| 에폭 83 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 15.05\n",
      "| 에폭 84 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 14.01\n",
      "| 에폭 85 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 13.07\n",
      "| 에폭 86 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 12.54\n",
      "| 에폭 87 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 12.14\n",
      "| 에폭 88 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 11.28\n",
      "| 에폭 89 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 10.79\n",
      "| 에폭 90 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 9.97\n",
      "| 에폭 91 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 9.58\n",
      "| 에폭 92 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 9.03\n",
      "| 에폭 93 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 8.71\n",
      "| 에폭 94 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 8.21\n",
      "| 에폭 95 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 8.26\n",
      "| 에폭 96 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 7.88\n",
      "| 에폭 97 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 6.92\n",
      "| 에폭 98 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 6.77\n",
      "| 에폭 99 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 6.50\n",
      "| 에폭 100 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 5.91\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5  # RNN을 펼치는 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  # 테스트 데이터셋을 작게 설정\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]  # 출력（정답 레이블）\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "trainer.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
