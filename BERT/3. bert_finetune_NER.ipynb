{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in c:\\programdata\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\jikim\\appdata\\roaming\\python\\python38\\site-packages (from seqeval) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from seqeval) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\programdata\\anaconda3\\lib\\site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertModel\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed 고정\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "MAX_LEN = 111 # EDA에서 추출된 Max Length\n",
    "DATA_IN_PATH = 'data_in/KOR'\n",
    "DATA_OUT_PATH = \"data_out/KOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개체명 인식 학습 데이터 개수: 81000\n",
      "개체명 인식 테스트 데이터 개수: 9000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>금석객잔 여러분, 감사드립니다 .</td>\n",
       "      <td>ORG-B O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이기범 한두 쪽을 먹고 10분 후쯤 화제인을 먹는 것이 좋다고 한다 .</td>\n",
       "      <td>PER-B O O O TIM-B TIM-I CVL-B O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-8위 결정전에서 김중배 무스파타(샌안토니오)가 참은 법국을 누르고 유럽축구선수권...</td>\n",
       "      <td>EVT-B EVT-I PER-B PER-I O LOC-B O EVT-B CVL-B O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>스코틀랜드의 한 마을에서 보통하게 살고 있다는 이 기혼 남성의 시조가 유튜브 등에서...</td>\n",
       "      <td>LOC-B NUM-B NUM-I O O O O O O O O O O O O O CV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>보니까 저 옆에 사조가 있어요 .</td>\n",
       "      <td>O O O O O O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0                                 금석객잔 여러분, 감사드립니다 .   \n",
       "1            이기범 한두 쪽을 먹고 10분 후쯤 화제인을 먹는 것이 좋다고 한다 .   \n",
       "2  7-8위 결정전에서 김중배 무스파타(샌안토니오)가 참은 법국을 누르고 유럽축구선수권...   \n",
       "3  스코틀랜드의 한 마을에서 보통하게 살고 있다는 이 기혼 남성의 시조가 유튜브 등에서...   \n",
       "4                                 보니까 저 옆에 사조가 있어요 .   \n",
       "\n",
       "                                               label  \n",
       "0                                        ORG-B O O O  \n",
       "1            PER-B O O O TIM-B TIM-I CVL-B O O O O O  \n",
       "2  EVT-B EVT-I PER-B PER-I O LOC-B O EVT-B CVL-B O O  \n",
       "3  LOC-B NUM-B NUM-I O O O O O O O O O O O O O CV...  \n",
       "4                                        O O O O O O  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리 준비\n",
    "DATA_TRAIN_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"train.tsv\")\n",
    "DATA_LABEL_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"label.txt\")\n",
    "DATA_TEST_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"test.tsv\")\n",
    "\n",
    "def read_file(input_path):\n",
    "    \"\"\"Read tsv file, and return words and label as list\"\"\"\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentences = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            split_line = line.strip().split(\"\\t\")\n",
    "            sentences.append(split_line[0])\n",
    "            labels.append(split_line[1])\n",
    "        return sentences, labels\n",
    "\n",
    "train_sentences, train_labels = read_file(DATA_TRAIN_PATH)\n",
    "\n",
    "train_ner_dict = {\"sentence\": train_sentences, \"label\": train_labels}\n",
    "train_ner_df = pd.DataFrame(train_ner_dict)\n",
    "\n",
    "\n",
    "\n",
    "test_sentences, test_labels = read_file(DATA_TEST_PATH)\n",
    "test_ner_dict = {\"sentence\": test_sentences, \"label\": test_labels}\n",
    "test_ner_df = pd.DataFrame(test_ner_dict)\n",
    "\n",
    "print(\"개체명 인식 학습 데이터 개수: {}\".format(len(train_ner_df)))\n",
    "print(\"개체명 인식 테스트 데이터 개수: {}\".format(len(test_ner_df)))\n",
    "\n",
    "# 개체명 인식 학습 데이터 개수: 81000\n",
    "# 개체명 인식 테스트 데이터 개수: 9000\n",
    "\n",
    "train_ner_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개체명 인식 레이블 개수: 30\n",
      "['UNK', 'O', 'PER-B', 'PER-I', 'FLD-B', 'FLD-I', 'AFW-B', 'AFW-I', 'ORG-B', 'ORG-I', 'LOC-B', 'LOC-I', 'CVL-B', 'CVL-I', 'DAT-B', 'DAT-I', 'TIM-B', 'TIM-I', 'NUM-B', 'NUM-I', 'EVT-B', 'EVT-I', 'ANM-B', 'ANM-I', 'PLT-B', 'PLT-I', 'MAT-B', 'MAT-I', 'TRM-B', 'TRM-I']\n"
     ]
    }
   ],
   "source": [
    "# Label 불러오기\n",
    "\n",
    "def get_labels(label_path):\n",
    "    return [label.strip() for label in open(os.path.join(label_path), 'r', encoding='utf-8')]\n",
    "\n",
    "ner_labels = get_labels(DATA_LABEL_PATH)\n",
    "\n",
    "print(\"개체명 인식 레이블 개수: {}\".format(len(ner_labels)))\n",
    "print(ner_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버트 토크나이저 설정\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert_ckpt')\n",
    "\n",
    "pad_token_id = tokenizer.pad_token_id # 0\n",
    "pad_token_label_id = 0\n",
    "cls_token_label_id = 0\n",
    "sep_token_label_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent,\n",
    "        truncation=True,\n",
    "        add_special_tokens = True, #'[CLS]'와 '[SEP]' 추가\n",
    "        max_length = MAX_LEN,           # 문장 패딩 및 자르기 진행\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True   # 어탠션 마스크 생성\n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask'] \n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id\n",
    "\n",
    "def convert_label(words, labels_idx, ner_begin_label, max_seq_len):\n",
    "            \n",
    "    tokens = []\n",
    "    label_ids = []\n",
    "\n",
    "    for word, slot_label in zip(words, labels_idx):\n",
    "\n",
    "#         print(word)\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "#         print(word_tokens)\n",
    "        \n",
    "        if not word_tokens:\n",
    "            word_tokens = [unk_token]\n",
    "        tokens.extend(word_tokens)\n",
    "        \n",
    "#         print(tokens)\n",
    "        \n",
    "        # 슬롯 레이블 값이 Begin이면 I로 추가\n",
    "        if int(slot_label) in ner_begin_label:\n",
    "            label_ids.extend([int(slot_label)] + [int(slot_label) + 1] * (len(word_tokens) - 1))\n",
    "        else:\n",
    "            label_ids.extend([int(slot_label)] * len(word_tokens))\n",
    "            \n",
    "#         print(label_ids)\n",
    "  \n",
    "    # [CLS] and [SEP] 설정\n",
    "    special_tokens_count = 2\n",
    "    if len(label_ids) > max_seq_len - special_tokens_count:\n",
    "        label_ids = label_ids[: (max_seq_len - special_tokens_count)]\n",
    "\n",
    "#     print(sep_token_label_id)\n",
    "    # [SEP] 토큰 추가\n",
    "    label_ids += [sep_token_label_id]\n",
    "\n",
    "#     print(cls_token_label_id)\n",
    "    # [CLS] 토큰 추가\n",
    "    label_ids = [cls_token_label_id] + label_ids\n",
    "    \n",
    "    padding_length = max_seq_len - len(label_ids)\n",
    "    label_ids = label_ids + ([pad_token_label_id] * padding_length)\n",
    "    \n",
    "#     print(label_ids)\n",
    "    \n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28]\n",
      "['PER-B', 'FLD-B', 'AFW-B', 'ORG-B', 'LOC-B', 'CVL-B', 'DAT-B', 'TIM-B', 'NUM-B', 'EVT-B', 'ANM-B', 'PLT-B', 'MAT-B', 'TRM-B']\n"
     ]
    }
   ],
   "source": [
    "# 테스트용\n",
    "ner_begin_label = [ner_labels.index(begin_label) for begin_label in ner_labels if \"B\" in begin_label]\n",
    "ner_begin_label_string = [ner_labels[label_index] for label_index in ner_begin_label]\n",
    "\n",
    "print(ner_begin_label)\n",
    "print(ner_begin_label_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs_targets(df):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "    label_list = []\n",
    "\n",
    "    for i, data in enumerate(df[['sentence', 'label']].values):\n",
    "        sentence, labels = data\n",
    "        words = sentence.split()\n",
    "        labels = labels.split()\n",
    "        labels_idx = []\n",
    "        \n",
    "#         print(labels)\n",
    "        \n",
    "        for label in labels:\n",
    "            labels_idx.append(ner_labels.index(label) if label in ner_labels else ner_labels.index(\"UNK\"))\n",
    "\n",
    "        assert len(words) == len(labels_idx)\n",
    "\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(sentence, MAX_LEN)\n",
    "\n",
    "#         print(\"words=\", words)\n",
    "#         print(\"labels_idx=\", labels_idx)\n",
    "#         print(\"ner_begin_label=\",ner_begin_label)\n",
    "        convert_label_id = convert_label(words, labels_idx, ner_begin_label, MAX_LEN)\n",
    "\n",
    "#         print(\"convert_label_id=\", convert_label_id)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        label_list.append(convert_label_id)\n",
    "#         break\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "    label_list = np.asarray(label_list, dtype=int) #레이블 토크나이징 리스트\n",
    "    inputs = (input_ids, attention_masks, token_type_ids)\n",
    "    \n",
    "    return inputs, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_inputs, train_labels = create_inputs_targets(train_ner_df)\n",
    "test_inputs, test_labels = create_inputs_targets(test_ner_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['금', '##석', '##객', '##잔']]\n",
      "[['금', '##석', '##객', '##잔'], ['여러', '##분', ',']]\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "token = ['금', '##석', '##객', '##잔']\n",
    "a.append(token)\n",
    "print(a)\n",
    "token = ['여러', '##분', ',']\n",
    "a.append(token)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['금', '##석', '##객', '##잔']\n",
      "['금', '##석', '##객', '##잔', '여러', '##분', ',']\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "token = ['금', '##석', '##객', '##잔']\n",
    "a.extend(token)\n",
    "print(a)\n",
    "token = ['여러', '##분', ',']\n",
    "a.extend(token)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "111\n",
      "[   101   8928  40958 118617 119196  30085  37712    117   8848  12945\n",
      "  15001  35115  48345    119    102      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0]\n",
      "[CLS] 금석객잔 여러분, 감사드립니다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[ C L S ] 금 # # 석 # # 객 # # 잔 여 러 # # 분 , 감 # # 사 # # 드 # # 립 # # 니 다 . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
      "[0 8 9 9 9 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "UNK ORG-B ORG-I ORG-I ORG-I O O O O O O O O O UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK "
     ]
    }
   ],
   "source": [
    "print(len(train_inputs[0][0]))\n",
    "print(len(train_labels[0]))\n",
    "print(train_inputs[0][0])\n",
    "print(tokenizer.decode(train_inputs[0][0]))\n",
    "for token in train_inputs[0][0]:\n",
    "    print(tokenizer.decode(int(token)), end=\" \")\n",
    "    \n",
    "print()\n",
    "print(train_labels[0])\n",
    "for label in train_labels[0]:\n",
    "    print(ner_labels[label], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertNERClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertNERClassifier, self).__init__()\n",
    "\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range),\n",
    "                                                name=\"ner_classifier\")  # (32,111,768)(768,30) => (32,111,30) ??\n",
    "\n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "\n",
    "        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[0]\n",
    "                \n",
    "        sequence_output = self.dropout(sequence_output, training=training)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "ner_model = TFBertNERClassifier(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt',\n",
    "                                  num_class=len(ner_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3],\n",
    "                 [4,5,6]])\n",
    "print(a)\n",
    "a.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 0]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 0], shape=(6,), dtype=int32)\n",
      "tf.Tensor([ True  True  True  True  True False], shape=(6,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3],\n",
    "                 [4,5,0]])\n",
    "print(a)\n",
    "b = tf.reshape(a, (-1,))\n",
    "print(b)\n",
    "c = b != 0\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  0]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10  0]]], shape=(2, 2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 4  5  0]\n",
      " [ 6  7  8]\n",
      " [ 9 10  0]], shape=(4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[[1,2,3],\n",
    "                  [4,5,0]],\n",
    "                 [[6,7,8],\n",
    "                  [9,10,0]]]\n",
    "                 )\n",
    "print(a)\n",
    "b = tf.reshape(a, (-1, a.get_shape().as_list()[2]))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ True  True  True False], shape=(4,), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]], shape=(4, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [6 7 8]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor([1 2 4], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "labels = tf.constant([[1,2],\n",
    "                      [4,0]])\n",
    "\n",
    "active_loss = tf.reshape(labels, (-1,)) != 0\n",
    "print(active_loss)\n",
    "\n",
    "logits = tf.constant([[[1,2,3],\n",
    "                       [4,5,6]],\n",
    "                      [[6,7,8],\n",
    "                       [9,10,11]]]\n",
    "                       )\n",
    "logits = tf.reshape(logits, (-1, logits.get_shape().as_list()[2]))\n",
    "print(logits)\n",
    "reduced_logits = tf.boolean_mask(logits, active_loss)\n",
    "print(reduced_logits)\n",
    "\n",
    "labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(labels, logits):\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE\n",
    "    )\n",
    "\n",
    "    # 0의 레이블 값은 손실 값을 계산할 때 제외\n",
    "    active_loss = tf.reshape(labels, (-1,)) != 0\n",
    "        \n",
    "#     reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])), active_loss)\n",
    "        \n",
    "    reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, logits.get_shape().as_list()[2])), active_loss)\n",
    "    \n",
    "    labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\n",
    "    \n",
    "    return loss_fn(labels, reduced_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:167: UserWarning: 1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:167: UserWarning: 2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "labels = [['1', '1', '1', '1', '2', '2', '2']]\n",
    "preds  = [['1', '1', '1', '1', '2', '2', '2']]\n",
    "precision = precision_score(labels, preds, suffix=True)\n",
    "print(precision)\n",
    "recall = recall_score(labels, preds, suffix=True)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def compute_f1_pre_rec(self, labels, preds):\n",
    "\n",
    "        return {\n",
    "            \"precision\": precision_score(labels, preds, suffix=True),\n",
    "            \"recall\": recall_score(labels, preds, suffix=True),\n",
    "            \"f1\": f1_score(labels, preds, suffix=True)\n",
    "        }\n",
    "\n",
    "\n",
    "    def show_report(self, labels, preds):\n",
    "        return classification_report(labels, preds, suffix=True)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        results = {}\n",
    "        \n",
    "        pred = self.model.predict(self.x_eval)\n",
    "        label = self.y_eval\n",
    "        pred_argmax = np.argmax(pred, axis = 2)\n",
    "\n",
    "        slot_label_map = {i: label for i, label in enumerate(ner_labels)}\n",
    "\n",
    "        out_label_list = [[] for _ in range(label.shape[0])]\n",
    "        preds_list = [[] for _ in range(label.shape[0])]\n",
    "\n",
    "        for i in range(label.shape[0]):\n",
    "            for j in range(label.shape[1]):\n",
    "                if label[i, j] != 0:\n",
    "                    out_label_list[i].append(slot_label_map[label[i][j]])\n",
    "                    preds_list[i].append(slot_label_map[pred_argmax[i][j]])\n",
    "                    \n",
    "        result = self.compute_f1_pre_rec(out_label_list, preds_list)\n",
    "        results.update(result)\n",
    "\n",
    "        print(\"********\")\n",
    "        print(\"F1 Score\")\n",
    "        for key in sorted(results.keys()):\n",
    "            print(\"{}, {:.4f}\".format(key, results[key]))\n",
    "        print(\"\\n\" + self.show_report(out_label_list, preds_list))\n",
    "        print(\"********\")\n",
    "\n",
    "f1_score_callback = F1Metrics(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "# ner_model.compile(optimizer=optimizer, loss=compute_loss, run_eagerly=True)\n",
    "ner_model.compile(optimizer=optimizer, loss=compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"tf2_bert_ner\"\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = ner_model.fit(train_inputs, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
    "                        callbacks=[cp_callback, f1_score_callback])\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.save_weights('weights_NER.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.load_weights('weights_NER.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 111)\n",
      "[   101   8982  16985  11287   9954   9477  15184  11261  20308  11513\n",
      "  23969   9672  11102 100699  10530  18154   9706 119285  12092  11506\n",
      "    119    102      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0]\n",
      "[CLS] 나아가 한 스트로크를 하는 제한시간에 대한 지침도 있다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[ C L S ] 나 # # 아 # # 가 한 스 # # 트 # # 로 # # 크 # # 를 하 는 제 # # 한 # # 시 간 # # 에 대 한 지 # # 침 # # 도 있 다 . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ 0  1  1  1 18 19 19 19 19 19  1  1  1  1  1  1  1  1  1  1  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "UNK O O O NUM-B NUM-I NUM-I NUM-I NUM-I NUM-I O O O O O O O O O O O UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK "
     ]
    }
   ],
   "source": [
    "print(test_inputs[0].shape)\n",
    "print(test_inputs[0][0])\n",
    "print(tokenizer.decode(test_inputs[0][0]))\n",
    "for token in test_inputs[0][0]:\n",
    "    print(tokenizer.decode(int(token)), end=\" \")\n",
    "    \n",
    "print(test_labels[0])\n",
    "for label in test_labels[0]:\n",
    "    print(ner_labels[label], end=\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 111, 30)\n",
      "[ C L S ]\n",
      "송\n",
      "# # 인\n",
      "# # 영\n",
      "# # 은\n",
      "5\n",
      "# # 년\n",
      "근\n",
      "# # 화\n",
      "# # 향\n",
      "# # 에 서\n",
      "개\n",
      "# # 최\n",
      "# # 된\n",
      "C J\n",
      "# # 나\n",
      "# # 인\n",
      "# # 브\n",
      "# # 릿\n",
      "# # 지\n",
      "# # 클\n",
      "# # 래\n",
      "# # 식\n",
      "토\n",
      "# # 요\n",
      "# # 돌\n",
      "# # 봄\n",
      "# # 으 로\n",
      "'\n",
      "L P\n",
      "# # G A\n",
      "직\n",
      "# # 행\n",
      "# # 티\n",
      "# # 킷\n",
      "'\n",
      "을\n",
      "거\n",
      "# # 머\n",
      "# # 쥐\n",
      "# # 었 던\n",
      "투\n",
      "# # 표\n",
      "# # 권\n",
      ".\n",
      "[ S E P ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "[ P A D ]\n",
      "\n",
      "[ 0  2  3  3  3 14 15 10 11 11 11  1  1  1 20 21 21 21 21 21 21 21 21 12\n",
      " 13 13 13 13  8  9  9  1  1  1  1  1  1  1  1  1  1 12 13 13  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "UNK PER-B PER-I PER-I PER-I DAT-B DAT-I LOC-B LOC-I LOC-I LOC-I O O O EVT-B EVT-I EVT-I EVT-I EVT-I EVT-I EVT-I EVT-I EVT-I CVL-B CVL-I CVL-I CVL-I CVL-I ORG-B ORG-I ORG-I O O O O O O O O O O CVL-B CVL-I CVL-I O UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK \n",
      "----------------------------------------------------------------------------------------------------\n",
      "PER-B PER-I PER-I PER-I DAT-B DAT-I LOC-B LOC-I LOC-I LOC-I O O O EVT-B EVT-I EVT-I EVT-I EVT-I EVT-I EVT-I EVT-I EVT-I CVL-B CVL-I CVL-I CVL-I CVL-I EVT-B EVT-I EVT-I CVL-B CVL-I CVL-I CVL-I CVL-I CVL-I O O O O O O O O "
     ]
    }
   ],
   "source": [
    "index=2\n",
    "my_inputs = (test_inputs[0][index:index+1,:],test_inputs[1][index:index+1,:],test_inputs[2][index:index+1,:])\n",
    "result = ner_model.predict(my_inputs)\n",
    "print(result.shape)\n",
    "\n",
    "for token in test_inputs[0][index]:\n",
    "    print(tokenizer.decode(int(token), end=\" \"))\n",
    "print()    \n",
    "\n",
    "print(test_labels[index])\n",
    "for label in test_labels[index]:\n",
    "    print(ner_labels[label], end=\" \")\n",
    "    \n",
    "print()\n",
    "print('-'*100, end='\\n')\n",
    "\n",
    "active_loss = test_labels[index] != 0\n",
    "reduced_logits = tf.boolean_mask(result[0], active_loss)\n",
    "\n",
    "ner = np.argmax(reduced_logits, axis=1)\n",
    "for label in ner:\n",
    "    print(ner_labels[label], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
